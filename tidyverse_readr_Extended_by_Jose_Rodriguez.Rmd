---
title: 'tidyverse: using readr to control column data types'
author: "Jhakim"
date: "10/25/2022"
output: html_document
---

# Load library
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
#library(forcats)
```

# Handy readr functions for working with CSV and other data formats

I was looking for a simple dataset with count data for many items to demonstrate some basic readr functions. Luckily, readr comes bundled with a good demo dataset.

```{r, warning=FALSE}
chickens <- read_csv(readr_example("chickens.csv"))
chickens
```

## 1A: Setting column data types

Q: how to I set column types?
A: Use readr column specifications

Column types have been printed by readr. The column types were *guessed* by readr, and although it has done a very good job, it is not perfect. For example, the guessed column type for *eggs_laid* is *double*. 

```{r}
spec(chickens)
```

Since chickens do not lay fractional eggs we may want to tell readr to set the type of eggs_laid as *integer*. Furthermore, we may also want *sex* to be read in as *factor* instead of *character*. Notice, we set specifications for only those columns that were not guessed correctly.

```{r}
chickens <- read_csv(readr_example("chickens.csv"),
                     col_types = cols(
                         sex = col_factor(levels = c('rooster', 'hen')),
                         eggs_laid = col_integer()
                     )
)
chickens
```

The column types have now been set correctly. A compact way of providing column types is by using a string of positional types. For example, `cfi` to read first column as character, second as float, and third as integer. To skip columns underscore character.

```{r}
chickens <- read_csv(readr_example("chickens.csv"),
                     col_types = cols(
                         sex = col_factor(levels = c('rooster', 'hen')),
                         eggs_laid = col_integer(),
                         .default = col_character()
                     )
)
chickens
```
Finally, a default type can be used for instead of guessing for columns that are not specified.

```{r}
chickens <- read_csv(readr_example("chickens.csv"),
                     col_types = "cfi_"
                     )
```

## 2A: Parsing atomic vectors

Q: how can I parse a character vector into specific data type
A: Use readr::parse_ functions

```{r}
parse_double(c('1.1', '2', '3', '4'))
parse_logical(c('t', 'f'))
```

Unlike parse_integer() and parse_double(), parse_number() is able to handle num-numeric prefixes and suffixes.

```{r}
parse_number(c('$123.45', '1,000,000'))
```

Finally, there are flexible Date/Time parsers.

```{r}
parse_datetime('2022-10-29 18:06')
parse_date('2022-10-29')
parse_time("3:08 pm")
```

The Date/Time  parsers takes an optional *format* argument that specifies the string format.

```{r}
parse_date("10/29/2022", format = "%m/%d/%Y")

```

# Extension

In addition to the above-mentioned functions from readr, col_skip() can be a very powerful tool to subset your data before its loaded into the environment. This function can be used to increase computing efficiency and reduce computing power costs if used at a large scale. In the example below we will remove *eggs_laid*.
```{r}
#Skipping a column
chickens1 <- read_csv(readr_example("chickens.csv"), col_types = cols('eggs_laid'=col_skip()))
chickens1
```

Another useful function in terms of scalability is read_delim_chunked(). This function allows its user to read a file in pieces and process it bit by bit. Very useful if ones system does not have enough ram memory space to allocate the whole file.
```{r}
f <- function(x, pos)
read_delim_chunked(readr_example("chickens.csv"),  DataFrameCallback$new(f), chunk_size = 5)
```


